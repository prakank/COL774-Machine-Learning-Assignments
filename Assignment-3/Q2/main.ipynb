{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, values_dict = {}, train_data = False):\n",
    "    df = np.asarray(pd.read_csv(filename, header=None, dtype=int))\n",
    "    Y = df[:,-1]\n",
    "    \n",
    "    df = df[:,0:df.shape[1]-1]\n",
    "    x = np.zeros((df.shape[0],85))\n",
    "    y = np.zeros((df.shape[0],len(list(set(list(Y))))))\n",
    "            \n",
    "    if values_dict == {}:\n",
    "        for i in range(df.shape[1]):\n",
    "            length = len(list(set(list(df[:,i]))))\n",
    "            values_dict[i] = length\n",
    "    \n",
    "    for j in range(df.shape[0]):\n",
    "        ohe_encoded = []\n",
    "        y[j][Y[j]] = 1\n",
    "        for i in range(df.shape[1]):\n",
    "            val = df[j][i]\n",
    "            ohe_mat = np.zeros((values_dict[i]))\n",
    "            ohe_mat[val-1] = 1\n",
    "            ohe_encoded.extend(ohe_mat)\n",
    "        ohe_encoded = np.asarray(ohe_encoded)\n",
    "        x[j] = ohe_encoded\n",
    "\n",
    "    if train_data == True:\n",
    "        return x,y,values_dict\n",
    "    else:\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PART = 'a'\n",
    "BASE_DIR = '../'\n",
    "\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'Poker_Hand_dataset', 'poker-hand-training-true.data')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'Poker_Hand_dataset', 'poker-hand-testing.data')\n",
    "\n",
    "# if PART == 'a':\n",
    "\n",
    "Xtrain, Ytrain, values_dict = load_data(train_path,train_data=True)\n",
    "Xtest, Ytest = load_data(test_path, values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUMBER_OF_INPUTS = 85\n",
    "HIDDEN_LAYERS_UNITS = [5]\n",
    "NUMBER_OF_OUTPUTS = 10\n",
    "LEARNING_RATE = 0.2\n",
    "EPSILON = 0.001\n",
    "tolerance = 0.001\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_architecture:\n",
    "    def __init__(self, learning_rate, batch_size, num_of_inputs, hidden_layer_units, num_of_outputs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "        self.hidden_layer_list = hidden_layer_units\n",
    "        self.num_of_outputs = num_of_outputs\n",
    "        self.learning_rate_threshold = 1e-5 # Min possible learning rate\n",
    "    \n",
    "    def sigmoid_activation(self,data):\n",
    "        return (1.0/(1.0 + np.exp(-data)) )\n",
    "    \n",
    "    def relu_activation(self,data):\n",
    "        return np.multiply(data>0,data)\n",
    "    \n",
    "    def sigmoid_der(self,data):\n",
    "        # x = self.sigmoid_activation(data)\n",
    "        x = data\n",
    "        return np.multiply(x,1.0-x)\n",
    "    \n",
    "    def relu_der(self,data):\n",
    "        temp = np.ones(data.shape,dtype=float)\n",
    "        return np.multiply(temp>0,temp)\n",
    "                    \n",
    "    def initialize(self):\n",
    "        neuron_count = [self.num_of_inputs]\n",
    "        neuron_count.extend(self.hidden_layer_list)\n",
    "        neuron_count.append(self.num_of_outputs)\n",
    "        self.neuron_count = neuron_count\n",
    "        params = {}\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        # xavier initialization\n",
    "        for i in range(1, len(neuron_count)):\n",
    "            params[\"W\" + str(i)] = np.random.normal(0,1,(neuron_count[i],neuron_count[i-1]))*np.sqrt(2.0/neuron_count[i-1])\n",
    "            params[\"b\" + str(i)] = np.zeros((neuron_count[i],1),dtype=float)\n",
    "        \n",
    "        self.params = params\n",
    "        self.num_of_layers = len(neuron_count)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def forward_propagation(self, X, activation_function):        \n",
    "        forward_prop = {}\n",
    "        data = (X.T).copy()\n",
    "        forward_prop[\"a0\"] = data # n*m\n",
    "\n",
    "        for i in range(self.num_of_layers-2):\n",
    "            data = np.dot(self.params[\"W\"+str(i+1)], data) + self.params[\"b\"+str(i+1)]\n",
    "\n",
    "            if activation_function == \"relu\":\n",
    "                data = self.relu_activation(data)\n",
    "            elif activation_function == \"sigmoid\":\n",
    "                data = self.sigmoid_activation(data)\n",
    "\n",
    "            forward_prop[\"a\"+str(i+1)] = data.copy()\n",
    "        \n",
    "        data = np.dot(self.params[\"W\"+str(self.num_of_layers-1)], data) + self.params[\"b\"+str(self.num_of_layers-1)]\n",
    "        data = self.sigmoid_activation(data)\n",
    "        forward_prop[\"a\"+str(self.num_of_layers-1)] = data.copy()\n",
    "\n",
    "        self.forward_prop = forward_prop\n",
    "        return\n",
    "    \n",
    "    def backward_propagation(self, Y, activation_function):\n",
    "        self.backward_prop = {}\n",
    "        dataY = (Y.T).copy()\n",
    "        \n",
    "        self.backward_prop[\"dz\"+str(self.num_of_layers-1)] = self.forward_prop[\"a\" + str(self.num_of_layers-1)] - dataY\n",
    "        \n",
    "        for i in range(self.num_of_layers-2,0,-1):\n",
    "            temp_mat = np.dot(self.params[\"W\"+str(i+1)].T, self.backward_prop[\"dz\"+str(i+1)])\n",
    "            \n",
    "            if activation_function == \"sigmoid\":\n",
    "                temp_mat =np.multiply(temp_mat, self.sigmoid_der(self.forward_prop[\"a\"+str(i)]))\n",
    "            elif activation_function == \"relu\":\n",
    "                temp_mat =np.multiply(temp_mat, self.relu_der(self.forward_prop[\"a\"+str(i)]))\n",
    "                \n",
    "            self.backward_prop[\"dz\"+str(i)] = temp_mat\n",
    "        \n",
    "        # i = self.num_of_layers-2\n",
    "        # while i>=0:\n",
    "        #     temp_mat = np.dot(self.params[\"W\"+str(i+1)].T, backward_prop[\"dz\" + str(i+1)])\n",
    "            \n",
    "        #     if activation_function == \"sigmoid\":\n",
    "        #         temp_mat = np.multiply(temp_mat, self.sigmoid_der(self.forward_prop[\"a\"+str(i)]))\n",
    "        #     elif activation_function == \"relu\":\n",
    "        #         temp_mat = np.multiply(temp_mat, self.relu_der(self.forward_prop[\"a\"+str(i)]))\n",
    "                \n",
    "        #     backward_prop[\"dz\" + str(i)] = temp_mat            \n",
    "        #     i-=1\n",
    "        # self.backward_prop = backward_prop\n",
    "        # return\n",
    "    \n",
    "    def backward_propagation2(self, Y, activation_function):\n",
    "        self.backward_prop = {}\n",
    "        dataY = (Y.T).copy()\n",
    "        \n",
    "        temp_mat = np.multiply(dataY - self.forward_prop[\"a\"+str(self.num_of_layers-1)], self.forward_prop[\"a\"+str(self.num_of_layers-1)])\n",
    "        temp_mat = np.multiply(temp_mat, (1-self.forward_prop[\"a\"+str(self.num_of_layers-1)]) )\n",
    "        \n",
    "        self.backward_prop[\"dz\"+str(self.num_of_layers-1)] = temp_mat\n",
    "        \n",
    "        for i in range(self.num_of_layers-2, 0, -1):\n",
    "            if activation_function == \"sigmoid\":\n",
    "                temp_mat = np.multiply(self.params[\"W\"+str(i+1)].T @ self.backward_prop[\"dz\"+str(i+1)], self.forward_prop[\"a\"+str(i)] * (1-self.forward_prop[\"a\"+str(i)]) )\n",
    "            elif activation_function == \"relu\":\n",
    "                temp_mat = temp_mat = np.multiply(self.params[\"W\"+str(i+1)].T @ self.backward_prop[\"dz\"+str(i+1)], np.multiply(self.forward_prop[\"a\"+str(i)] > 0, self.forward_prop[\"a\"+str(i)]) )\n",
    "        \n",
    "            self.backward_prop[\"dz\"+str(i)] = temp_mat\n",
    "        return\n",
    "                    \n",
    "    def update_params(self,M):\n",
    "        new_params = {}\n",
    "        for i in range(1,self.num_of_layers):\n",
    "            new_params[\"W\"+str(i)] = self.params[\"W\"+str(i)] - (self.learning_rate/M)*np.dot(self.backward_prop[\"dz\"+str(i)],(self.forward_prop[\"a\"+str(i-1)]).T)\n",
    "            \n",
    "            temp = (self.learning_rate/M)*np.sum(self.backward_prop[\"dz\"+str(i)],axis=1)\n",
    "            temp = temp.reshape((temp.shape[0],1))\n",
    "            \n",
    "            new_params[\"b\"+str(i)] = self.params[\"b\"+str(i)] - temp\n",
    "            \n",
    "        self.params = new_params\n",
    "        return\n",
    "    \n",
    "    def predict(self,X,activation_function=\"sigmoid\"):\n",
    "        data_x = (X.T).copy()\n",
    "        for i in range(1,self.num_of_layers):\n",
    "            data_x = np.add(np.dot(self.params[\"W\"+str(i)],data_x),self.params[\"b\"+str(i)])\n",
    "            if activation_function == \"sigmoid\":\n",
    "                data_x = self.sigmoid_activation(data_x)\n",
    "                \n",
    "            elif activation_function == \"relu\":\n",
    "                data_x = self.relu_activation(data_x)    \n",
    "        \n",
    "        data_x = self.sigmoid_activation(data_x)\n",
    "        data_x = data_x.T\n",
    "        data_x = data_x/(np.sum(data_x,axis=1).reshape(data_x.shape[0],1))\n",
    "                \n",
    "        return data_x, np.argmax(data_x,axis=1)\n",
    "    \n",
    "    def loss_function(self,y1,y2):\n",
    "        # print(y1,y2)\n",
    "        y = np.abs(y1-y2)\n",
    "        y = np.multiply(y,y)\n",
    "        return np.sum(y)/(2*y.shape[0])\n",
    "    \n",
    "    def print_param(self, i):\n",
    "        print(\"Iteration: {}\".format(i))\n",
    "        for i in self.params:\n",
    "            print(i,np.max(self.params[i]), np.min(self.params[i]), self.params[i].shape)\n",
    "        print()\n",
    "\n",
    "        for i in self.backward_prop:\n",
    "            print(i,np.max(self.backward_prop[i]), np.min(self.backward_prop[i]), self.backward_prop[i].shape)\n",
    "        print()    \n",
    "\n",
    "        for i in self.forward_prop:\n",
    "            print(i,np.max(self.forward_prop[i]), np.min(self.forward_prop[i]), self.forward_prop[i].shape)\n",
    "        print()\n",
    "    \n",
    "    def print_class_param(self):\n",
    "        print(\"Batch Size: {}, Learning rate: {}, Num of layers: {}\".format(self.batch_size, self.learning_rate, self.num_of_layers))\n",
    "        print(\"Neuron count: {}\".format(self.neuron_count))\n",
    "\n",
    "    def batch_loss(self, y1, y2):\n",
    "        \n",
    "        # Here y2 is the actual Y\n",
    "        # y1 is the predicted y\n",
    "        l1 = np.log(np.multiply(1, y1==0) + y1)\n",
    "        l1 = np.multiply(l1, y2)\n",
    "        \n",
    "        l2 = np.log(np.multiply(1, y1==1) + 1 - y1)\n",
    "        l2 = np.multiply(l2, 1-y2)\n",
    "        \n",
    "        l = np.mean(-1.0*l1-1.0*l2,axis=1)\n",
    "        l = np.sqrt(np.sum(np.multiply(l,l)))/(2.0*y1.shape[1])\n",
    "        \n",
    "        return l\n",
    "        \n",
    "\n",
    "    def run(self,epochs,epsilon,X,Y,activation_function,adaptive=False):\n",
    "        \n",
    "        self.examples = X.shape[0]\n",
    "        self.batches = (int)(self.examples/self.batch_size)        \n",
    "        self.initialize()\n",
    "        # self.print_param(0)\n",
    "        # self.print_class_param()\n",
    "        \n",
    "        iteration  = 1\n",
    "        error = float(\"inf\")        \n",
    "        time_start = time.time()\n",
    "        print(\"Training phase ... \")\n",
    "        \n",
    "        error_list = []\n",
    "        \n",
    "        while iteration <= epochs and error > epsilon and self.learning_rate > self.learning_rate_threshold:\n",
    "            \n",
    "            error = 0\n",
    "            for batch in range(self.batches):\n",
    "                start = batch*self.batch_size\n",
    "                end   = min(start + self.batch_size,self.examples)\n",
    "\n",
    "                X_new = X[start:end,:]\n",
    "                Y_new = Y[start:end,:]\n",
    "\n",
    "                self.forward_propagation(X_new,activation_function)\n",
    "\n",
    "                # self.backward_propagation2(Y_new,activation_function)\n",
    "                self.backward_propagation(Y_new,activation_function)\n",
    "\n",
    "                self.update_params(Y_new.shape[0])\n",
    "\n",
    "                loss_partial = self.batch_loss(self.forward_prop[\"a\"+str(self.num_of_layers-1)], Y_new.T)\n",
    "                error += (loss_partial)\n",
    "            \n",
    "            error_list.append(error)\n",
    "            \n",
    "            if iteration%10 == 0:\n",
    "                print(\"Epoch: {}, Error: {}\".format(iteration, error))            \n",
    "            iteration += 1\n",
    "            \n",
    "            if adaptive:\n",
    "                self.learning_rate = (self.init_learning_rate)/(np.sqrt(iteration))\n",
    "        \n",
    "        time_end = time.time()\n",
    "        self.training_time = (time_end - time_start)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase ... \n",
      "Epoch: 10, Error: 1.2530753030433384\n",
      "Epoch: 20, Error: 1.253038962173449\n",
      "Epoch: 30, Error: 1.253020327680691\n",
      "Epoch: 40, Error: 1.253009128543071\n",
      "Epoch: 50, Error: 1.253001628856403\n",
      "Epoch: 60, Error: 1.2529962052201846\n",
      "Epoch: 70, Error: 1.2529920460867472\n",
      "Epoch: 80, Error: 1.2529887039923056\n",
      "Epoch: 90, Error: 1.252985913980883\n",
      "Epoch: 100, Error: 1.2529835104225455\n",
      "Epoch: 110, Error: 1.252981385254278\n",
      "Epoch: 120, Error: 1.252979465479124\n",
      "Epoch: 130, Error: 1.2529777003405835\n",
      "Epoch: 140, Error: 1.2529760536690588\n",
      "Epoch: 150, Error: 1.2529744991371412\n",
      "Epoch: 160, Error: 1.2529730172217388\n",
      "Epoch: 170, Error: 1.2529715932043946\n",
      "Epoch: 180, Error: 1.2529702158228901\n",
      "Epoch: 190, Error: 1.2529688763426126\n",
      "Epoch: 200, Error: 1.2529675679048597\n",
      "Epoch: 210, Error: 1.2529662850618093\n",
      "Epoch: 220, Error: 1.2529650234396164\n",
      "Epoch: 230, Error: 1.252963779491003\n",
      "Epoch: 240, Error: 1.2529625503112782\n",
      "Epoch: 250, Error: 1.252961333499987\n",
      "Epoch: 260, Error: 1.2529601270557456\n",
      "Epoch: 270, Error: 1.2529589292955594\n",
      "Epoch: 280, Error: 1.2529577387923454\n",
      "Epoch: 290, Error: 1.2529565543261643\n",
      "Epoch: 300, Error: 1.25295537484584\n",
      "Epoch: 310, Error: 1.2529541994385476\n",
      "Epoch: 320, Error: 1.2529530273055447\n",
      "Epoch: 330, Error: 1.2529518577426866\n",
      "Epoch: 340, Error: 1.2529506901246628\n",
      "Epoch: 350, Error: 1.25294952389221\n",
      "Epoch: 360, Error: 1.2529483585416499\n",
      "Epoch: 370, Error: 1.2529471936162944\n",
      "Epoch: 380, Error: 1.252946028699358\n",
      "Epoch: 390, Error: 1.252944863408071\n",
      "Epoch: 400, Error: 1.252943697388782\n",
      "Epoch: 410, Error: 1.2529425303128543\n",
      "Epoch: 420, Error: 1.2529413618732108\n",
      "Epoch: 430, Error: 1.2529401917814393\n",
      "Epoch: 440, Error: 1.252939019765308\n",
      "Epoch: 450, Error: 1.2529378455666829\n",
      "Epoch: 460, Error: 1.252936668939732\n",
      "Epoch: 470, Error: 1.2529354896493918\n",
      "Epoch: 480, Error: 1.252934307470046\n",
      "Epoch: 490, Error: 1.2529331221843922\n",
      "Epoch: 500, Error: 1.2529319335824514\n",
      "Epoch: 510, Error: 1.2529307414607143\n",
      "Epoch: 520, Error: 1.2529295456213967\n",
      "Epoch: 530, Error: 1.2529283458717821\n",
      "Epoch: 540, Error: 1.252927142023657\n",
      "Epoch: 550, Error: 1.252925933892799\n",
      "Epoch: 560, Error: 1.252924721298538\n",
      "Epoch: 570, Error: 1.2529235040633633\n",
      "Epoch: 580, Error: 1.2529222820125723\n",
      "Epoch: 590, Error: 1.252921054973956\n",
      "Epoch: 600, Error: 1.2529198227775362\n",
      "Epoch: 610, Error: 1.2529185852552946\n",
      "Epoch: 620, Error: 1.2529173422409725\n",
      "Epoch: 630, Error: 1.2529160935698516\n",
      "Epoch: 640, Error: 1.252914839078585\n",
      "Epoch: 650, Error: 1.2529135786050292\n",
      "Epoch: 660, Error: 1.2529123119880958\n",
      "Epoch: 670, Error: 1.252911039067613\n",
      "Epoch: 680, Error: 1.2529097596842111\n",
      "Epoch: 690, Error: 1.2529084736792009\n",
      "Epoch: 700, Error: 1.2529071808944796\n",
      "Epoch: 710, Error: 1.2529058811724259\n",
      "Epoch: 720, Error: 1.2529045743558254\n",
      "Epoch: 730, Error: 1.2529032602877852\n",
      "Epoch: 740, Error: 1.252901938811661\n",
      "Epoch: 750, Error: 1.2529006097709898\n",
      "Epoch: 760, Error: 1.2528992730094308\n",
      "Epoch: 770, Error: 1.2528979283707007\n",
      "Epoch: 780, Error: 1.252896575698531\n",
      "Epoch: 790, Error: 1.2528952148366117\n",
      "Epoch: 800, Error: 1.2528938456285488\n",
      "Epoch: 810, Error: 1.2528924679178175\n",
      "Epoch: 820, Error: 1.252891081547734\n",
      "Epoch: 830, Error: 1.2528896863614105\n",
      "Epoch: 840, Error: 1.2528882822017269\n",
      "Epoch: 850, Error: 1.2528868689112964\n",
      "Epoch: 860, Error: 1.2528854463324453\n",
      "Epoch: 870, Error: 1.2528840143071798\n",
      "Epoch: 880, Error: 1.2528825726771646\n",
      "Epoch: 890, Error: 1.252881121283709\n",
      "Epoch: 900, Error: 1.2528796599677399\n",
      "Epoch: 910, Error: 1.2528781885697846\n",
      "Epoch: 920, Error: 1.2528767069299627\n",
      "Epoch: 930, Error: 1.2528752148879683\n",
      "Epoch: 940, Error: 1.2528737122830602\n",
      "Epoch: 950, Error: 1.252872198954051\n",
      "Epoch: 960, Error: 1.2528706747393024\n",
      "Epoch: 970, Error: 1.252869139476714\n",
      "Epoch: 980, Error: 1.2528675930037239\n",
      "Epoch: 990, Error: 1.2528660351573069\n",
      "Epoch: 1000, Error: 1.2528644657739694\n",
      "Training time: 114.099s\n"
     ]
    }
   ],
   "source": [
    "model = NN_architecture(LEARNING_RATE,BATCH_SIZE,NUMBER_OF_INPUTS,[5, 5],NUMBER_OF_OUTPUTS)\n",
    "model.run(1000, EPSILON, Xtrain, Ytrain,'sigmoid',adaptive=False)\n",
    "\n",
    "print(\"Training time: {}s\".format(round(model.training_time,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 49.952%, Error: 0.4348318820233563\n",
      "Test Accuracy: 50.121%, Error: 0.43482004821381637\n",
      "[[501209      0      0      0      0      0      0      0      0      0]\n",
      " [422498      0      0      0      0      0      0      0      0      0]\n",
      " [ 47622      0      0      0      0      0      0      0      0      0]\n",
      " [ 21121      0      0      0      0      0      0      0      0      0]\n",
      " [  3885      0      0      0      0      0      0      0      0      0]\n",
      " [  1996      0      0      0      0      0      0      0      0      0]\n",
      " [  1424      0      0      0      0      0      0      0      0      0]\n",
      " [   230      0      0      0      0      0      0      0      0      0]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "y_class_train, y_pred_train = model.predict(Xtrain,'sigmoid')\n",
    "error = model.loss_function(y_class_train, Ytrain)\n",
    "print(\"Train Accuracy: {}%, Error: {}\".format(round(100*accuracy_score(y_pred_train, np.argmax(Ytrain,axis=1)),3), error))\n",
    "\n",
    "y_class_test, y_pred_test = model.predict(Xtest,'sigmoid')\n",
    "error2 = model.loss_function(y_class_test, Ytest)\n",
    "print(\"Test Accuracy: {}%, Error: {}\".format(round(100*accuracy_score(y_pred_test, np.argmax(Ytest,axis=1)),3), error2))\n",
    "\n",
    "y_conf = np.argmax(Ytest, axis=1)\n",
    "confusion_matrix = np.zeros((10,10))\n",
    "for i in range(Ytest.shape[0]):\n",
    "    confusion_matrix[y_conf[i]][y_pred_test[i]] += 1\n",
    "\n",
    "confusion_matrix = confusion_matrix.astype(int)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "#  5  10  15  20  25\n",
    "# 51, 55, 55  55  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 0.6159433781072531 -0.5049561528689354 (100, 85)\n",
      "b1 0.03445102346635879 -0.026007391987375665 (100, 1)\n",
      "W2 0.6012644202711865 -0.5026017293875579 (100, 100)\n",
      "b2 0.06744211180635681 -0.046595278571981626 (100, 1)\n",
      "W3 0.5863420821983738 -0.27864917905740544 (10, 100)\n",
      "b3 0.22454948086129342 0.16349251670983755 (10, 1)\n",
      "\n",
      "dz3 5.835407169399111e-08 -0.0002621945302480613 (10, 100)\n",
      "dz2 3.528285792021057e-05 -9.947474680130935e-05 (100, 100)\n",
      "dz1 3.4465562330752285e-05 -8.680280428545231e-05 (100, 100)\n",
      "\n",
      "a0 1.0 0.0 (85, 100)\n",
      "a1 0.8642525617767342 0.13003704924674026 (100, 100)\n",
      "a2 0.958915189777472 0.17342259559126652 (100, 100)\n",
      "a3 0.9998281509721083 0.9997376678514929 (10, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in model.params:\n",
    "    print(i,np.max(model.params[i]), np.min(model.params[i]), model.params[i].shape)\n",
    "print()\n",
    "\n",
    "for i in model.backward_prop:\n",
    "    print(i,np.max(model.backward_prop[i]), np.min(model.backward_prop[i]), model.backward_prop[i].shape)\n",
    "print()    \n",
    "\n",
    "for i in model.forward_prop:\n",
    "    print(i,np.max(model.forward_prop[i]), np.min(model.forward_prop[i]), model.forward_prop[i].shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (5, 25010)\n",
      "2 (10, 25010)\n",
      "0.3425029988004798 0.8999999765695527\n",
      "1 (5, 1000000)\n",
      "2 (10, 1000000)\n",
      "0.340879 0.8999999768439552\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09774662 0.05943147 0.13015246 0.06003993 0.06181143 0.06969242\n",
      " 0.14298412 0.12182448 0.13628063 0.12003645] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_class_train[1], Ytrain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase ... \n",
      "Epoch: 10, Error: 1.3209447245451744\n",
      "Epoch: 20, Error: 1.309657894758027\n",
      "Epoch: 30, Error: 1.2698166477909654\n",
      "Epoch: 40, Error: 1.3050447677498611\n",
      "Epoch: 50, Error: 3.726864440979116\n",
      "Epoch: 60, Error: 1.2916355433426845\n",
      "Epoch: 70, Error: 1.333688563643145\n",
      "Epoch: 80, Error: 1.268991924825986\n",
      "Epoch: 90, Error: 1.5195353628179034\n",
      "Epoch: 100, Error: nan\n",
      "Training time: 13.821s\n"
     ]
    }
   ],
   "source": [
    "model2 = NN_architecture(LEARNING_RATE,BATCH_SIZE,NUMBER_OF_INPUTS,[5, 5],NUMBER_OF_OUTPUTS)\n",
    "model2.run(1000, EPSILON, Xtrain, Ytrain,'relu')\n",
    "print(\"Training time: {}s\".format(round(model2.training_time,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 49.952%, Error: nan\n",
      "Test Accuracy: 50.121%, Error: nan\n",
      "[[501209      0      0      0      0      0      0      0      0      0]\n",
      " [422498      0      0      0      0      0      0      0      0      0]\n",
      " [ 47622      0      0      0      0      0      0      0      0      0]\n",
      " [ 21121      0      0      0      0      0      0      0      0      0]\n",
      " [  3885      0      0      0      0      0      0      0      0      0]\n",
      " [  1996      0      0      0      0      0      0      0      0      0]\n",
      " [  1424      0      0      0      0      0      0      0      0      0]\n",
      " [   230      0      0      0      0      0      0      0      0      0]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "y_class_train, y_pred_train = model2.predict(Xtrain,'relu')\n",
    "error = model2.loss_function(y_class_train, Ytrain)\n",
    "print(\"Train Accuracy: {}%, Error: {}\".format(round(100*accuracy_score(y_pred_train, np.argmax(Ytrain,axis=1)),3), error))\n",
    "\n",
    "y_class_test, y_pred_test = model2.predict(Xtest,'relu')\n",
    "error2 = model2.loss_function(y_class_test, Ytest)\n",
    "print(\"Test Accuracy: {}%, Error: {}\".format(round(100*accuracy_score(y_pred_test, np.argmax(Ytest,axis=1)),3), error2))\n",
    "\n",
    "y_conf = np.argmax(Ytest, axis=1)\n",
    "confusion_matrix = np.zeros((10,10))\n",
    "for i in range(Ytest.shape[0]):\n",
    "    confusion_matrix[y_conf[i]][y_pred_test[i]] += 1\n",
    "\n",
    "confusion_matrix = confusion_matrix.astype(int)\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "#  5  10  15  20  25\n",
    "# 51, 55, 55  55  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz4 1.0 -1.0 (10, 100)\n",
      "dz3 6.435164271970555e+42 -4.404224181042292 (10, 100)\n",
      "dz2 8.815363775156895e+84 -3.502298235246524e+42 (50, 100)\n",
      "dz1 1.8566504146402347e+127 -1.0062145051098991e+85 (70, 100)\n",
      "dz0 2.961153975535918e+169 4.476963190857688e+167 (85, 100)\n",
      "\n",
      "a0 1.0 0.0 (85, 100)\n",
      "z1 1.7200192885385603e+42 -1.4085656221727102e+28 (70, 100)\n",
      "a1 1.7200192885385603e+42 -0.0 (70, 100)\n",
      "z2 5.719136015978563e+84 -3.3449375096514033e+70 (50, 100)\n",
      "a2 5.719136015978563e+84 -0.0 (50, 100)\n",
      "z3 3.0859791960474724e+127 -2.210107472982474e+113 (10, 100)\n",
      "a3 3.0859791960474724e+127 -0.0 (10, 100)\n",
      "z4 2.9184023788594952e+169 -3.2059813725977796e+168 (10, 100)\n",
      "a4 1.0 0.0 (10, 100)\n",
      "\n",
      "W1 5.187071734070013e+125 -2.811141384889173e+83 (70, 85)\n",
      "b1 1.6732545734748368e+126 -9.068228511386736e+83 (70, 1)\n",
      "W2 1.235903635889553e+126 -4.910180944669756e+83 (50, 70)\n",
      "b2 7.944601545511659e+83 -3.1563489247030058e+41 (50, 1)\n",
      "W3 2.9998608977374687e+126 -1.698756360041152e+84 (10, 50)\n",
      "b3 5.799512910039699e+41 -2.2724962138505926 (10, 1)\n",
      "W4 2.5157662206256348e+126 -2.7542444682734613e+125 (10, 10)\n",
      "b4 0.658102131925157 -0.03195479892102392 (10, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in model2.backward_prop:\n",
    "    print(i,np.max(model2.backward_prop[i]), np.min(model2.backward_prop[i]), model2.backward_prop[i].shape)\n",
    "print()\n",
    "\n",
    "for i in model2.forward_prop:\n",
    "    print(i,np.max(model2.forward_prop[i]), np.min(model2.forward_prop[i]), model2.forward_prop[i].shape)\n",
    "print()\n",
    "\n",
    "for i in model2.params:\n",
    "    print(i,np.max(model2.params[i]), np.min(model2.params[i]), model2.params[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.forward_prop[\"a1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.neuron_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params[\"W2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params[\"b1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params[\"b2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params[\"W1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params[\"W2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
