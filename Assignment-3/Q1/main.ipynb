{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'\n",
    "\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'bank_dataset', 'bank_train.csv')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'bank_dataset', 'bank_test.csv')\n",
    "val_path   = os.path.join(BASE_DIR, 'data', 'bank_dataset', 'bank_val.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, delimiter = ';')\n",
    "    Y = df['y']\n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i] == 'yes':\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0 #Assigning 0 to nan values\n",
    "\n",
    "    df = df.drop(['y'],axis=1)\n",
    "    return df, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_num(X,Y):\n",
    "    median = np.median(X)\n",
    "    boolean_flag = X > median\n",
    "    # X_left  = X[boolean_flag == True]\n",
    "    # X_right = X[boolean_flag == False]\n",
    "    Y_left  = Y[boolean_flag == True]\n",
    "    Y_right = Y[boolean_flag == False]\n",
    "    \n",
    "    p1,p2 = 0,0\n",
    "    \n",
    "    if Y_left.shape[0] > 0:\n",
    "        s1 = np.sum(Y_left)\n",
    "        s1 = max(s1, Y_left.shape[0] - s1)\n",
    "        p1 = float(s1)/float(Y_left.shape[0])\n",
    "        p1 = - p1 * np.log(p1)\n",
    "        p1 = p1*(float(Y_left.shape[0]))/float(Y.shape[0])\n",
    "    \n",
    "    if Y_right.shape[0] > 0:\n",
    "        s2 = np.sum(Y_right)\n",
    "        s2 = max(s2, Y_right.shape[0] - s2)\n",
    "        p2 = float(s2)/float(Y_right.shape[0])\n",
    "        p2 = - p2 * np.log(p2)\n",
    "        p2 = p2*(float(Y_right.shape[0]))/float(Y_right.shape[0])\n",
    "    \n",
    "    return p1+p2\n",
    "\n",
    "def entropy_categorical(X,Y):\n",
    "    val = list(set(list(X)))\n",
    "    val_count = dict.fromkeys(val,[0,0])\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        val_count[X[i]][1] += 1\n",
    "        if val_count[Y[i]] == 1:\n",
    "            val_count[X[i]][0] += 1\n",
    "\n",
    "    entr = 0\n",
    "\n",
    "    for category,count in val_count.items():\n",
    "        p = 0\n",
    "        val_count[category][0] = max(count[0], count[1] - count[0])\n",
    "        if count[1] > 0:\n",
    "            p = float(count[0])/float(count[1])\n",
    "            p = -p * np.log(p)\n",
    "            p = p * (float(count[1]))/float(Y.shape[0])        \n",
    "        entr += p\n",
    "    \n",
    "    return entr\n",
    "\n",
    "\n",
    "\n",
    "def information_gain(attribute, one_hot_encoding, numeric_cols, indices, X, Y):\n",
    "    X_new = np.array((X[indices])[attribute])\n",
    "    Y_new = Y[indices]\n",
    "    entr  = 0\n",
    "    info_parent = 0\n",
    "    \n",
    "    if attribute in numeric_cols:\n",
    "        entr = entropy_num(X_new, Y_new)\n",
    "    else:\n",
    "        if one_hot_encoding == False: # Multi split\n",
    "            entr = entropy_categorical(X_new, Y_new)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return info_parent - entr\n",
    "\n",
    "\n",
    "\n",
    "def best_attribute(one_hot_encoding, numeric_cols, indices, X, Y):\n",
    "    best_attr = ''\n",
    "    info_gain = -float('inf')\n",
    "    \n",
    "    for attr in X.columns:\n",
    "        temp = information_gain(attr, one_hot_encoding, numeric_cols, indices, X, Y)\n",
    "        if temp > info_gain:\n",
    "            info_gain = temp\n",
    "            best_attr = attr\n",
    "    \n",
    "    return best_attr\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(one_hot_encoding, numeric_cols, X, Y):\n",
    "    indices = np.arange(0,X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3251931052.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_357876/3251931052.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def __init__(self,parent,indices,):\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class dc_node:\n",
    "    \n",
    "    # indices coming at this node\n",
    "    def __init__(self,parent,indices):\n",
    "        self.parent = parent\n",
    "        self.indices = indices\n",
    "        self.child = []\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain = load_data(train_path)\n",
    "Xtest, Ytest = load_data(test_path)\n",
    "Xval, Yval = load_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PART = 'a'\n",
    "\n",
    "if PART == 'a':\n",
    "    all_columns = Xtrain.columns\n",
    "    categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "    numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_num(X,Y):\n",
    "    median = np.median(X)\n",
    "    boolean_flag = X > median\n",
    "    X_left = X[boolean_flag == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([7,7,7,7,5,6,7,8,9,10,11])\n",
    "me = np.median(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_mask = x > me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "x_l = x[bool_mask == True]\n",
    "print(x_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     4522\n",
      "unique       2\n",
      "top         no\n",
      "freq      4007\n",
      "Name: y, dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
