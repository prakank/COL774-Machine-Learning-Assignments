{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "def _stem(doc, p_stemmer, en_stop, return_tokens):\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    stopped_tokens = filter(lambda token: token not in en_stop, tokens)\n",
    "    stemmed_tokens = map(lambda token: p_stemmer.stem(token), stopped_tokens)\n",
    "    if not return_tokens:\n",
    "        return ' '.join(stemmed_tokens)\n",
    "    return list(stemmed_tokens)\n",
    "\n",
    "def getStemmedDocuments(docs, return_tokens=True):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            docs: str/list(str): document or list of documents that need to be processed\n",
    "            return_tokens: bool: return a re-joined string or tokens\n",
    "        Returns:\n",
    "            str/list(str): processed document or list of processed documents\n",
    "        Example: \n",
    "            new_text = \"It is important to by very pythonly while you are pythoning with python. \\\n",
    "                All pythoners have pythoned poorly at least once.\"\n",
    "            print(getStemmedDocuments(new_text))\n",
    "        Reference: https://pythonprogramming.net/stemming-nltk-tutorial/\n",
    "    \"\"\"\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    if isinstance(docs, list):\n",
    "        output_docs = []\n",
    "        for item in docs:\n",
    "            output_docs.append(_stem(item, ps, en_stop, return_tokens))\n",
    "        return output_docs\n",
    "    else:\n",
    "        return _stem(docs, ps, en_stop, return_tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nltk.download()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "LaplaceSmoothing = 1\n",
    "BASE_DIR = \"../\"\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'reviews_Digital_Music_5.json', 'Music_Review_train.json')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'reviews_Digital_Music_5.json', 'Music_Review_test.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_json(filename, lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def clean_data(line):\n",
    "    line = line.strip().lower()\n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "    line = re.sub('\\r?\\n',' ',line)\n",
    "    return line\n",
    "\n",
    "def preprocessing(df, stemming):\n",
    "    ColumnsToDrop = ['reviewerID', 'asin', 'reviewerName', 'unixReviewTime', 'reviewTime']\n",
    "    df = df.drop(ColumnsToDrop, axis=1)\n",
    "    \n",
    "    df['reviewText'].apply(lambda x: clean_data(x))\n",
    "    df['summary'].apply(lambda x: clean_data(x))\n",
    "    \n",
    "    if stemming:\n",
    "        df['reviewText'].apply(lambda x: getStemmedDocuments(x))\n",
    "        df['summary'].apply(lambda x: getStemmedDocuments(x))\n",
    "        # for i in range(df.shape[0]):\n",
    "        #     print(i)\n",
    "        #     df.iloc[i,1] = getStemmedDocuments(df.iloc[i,1], False)\n",
    "        #     df.iloc[i,3] = getStemmedDocuments(df.iloc[i,3], False)    \n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def Vocab_generation(df1, df2):\n",
    "    VocabSize = 0\n",
    "    Vocab = dict()\n",
    "    \n",
    "    min_val = min(df2)\n",
    "    max_val = max(df2)\n",
    "    \n",
    "    VocabClassSize = [0]*(max_val - min_val + 1)\n",
    "    ExampleSize    = [0]*(max_val - min_val + 1)    \n",
    "        \n",
    "    for i,review in enumerate(df1):\n",
    "        for word in review.split():\n",
    "            if word not in Vocab:\n",
    "                Vocab[word] = 1\n",
    "                VocabSize  += 1\n",
    "\n",
    "    VocabClass = []\n",
    "    for i in range(max_val - min_val + 1):\n",
    "        d = Vocab.copy()\n",
    "        VocabClass.append(d)\n",
    "    \n",
    "    for i,review in enumerate(df1):\n",
    "        ExampleSize[df2[i]-min_val] += 1\n",
    "        for word in review.split():\n",
    "            VocabClassSize[df2[i]-min_val] += 1\n",
    "            VocabClass[df2[i]-min_val][word] += 1\n",
    "    \n",
    "    return Vocab, VocabClass, VocabSize, VocabClassSize, ExampleSize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "part_d = False\n",
    "\n",
    "train_data = preprocessing(load_data(train_path), part_d)\n",
    "test_data  = preprocessing(load_data(test_path), part_d)\n",
    "\n",
    "X_train = train_data['reviewText'].copy()\n",
    "Y_train = train_data['overall'].copy()\n",
    "\n",
    "X_test = test_data['reviewText'].copy()\n",
    "Y_test = test_data['overall'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "v1, v2, v3, v4, v5 = Vocab, VocabClass, VocabSize, VocabClassSize, phi\n",
    "print(phi)\n",
    "print(VocabClassSize)\n",
    "# print(VocabClass)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2529, 2638, 5634, 13267, 25932]\n",
      "[328626, 470556, 1183227, 2902715, 4954673]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# for i in range(len(VocabClass)):\n",
    "#     for x in VocabClass[i]:\n",
    "#         if(VocabClass[i][x] <= 0):\n",
    "#             print(\"ERROR\",i,x)\n",
    "#         else:\n",
    "#             np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "# print(\"DONE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        if(VocabClass[i][x] <= 0):\n",
    "            print(\"ERROR FOR CLASS:\",i)\n",
    "        else:\n",
    "            VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "    \n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "def predict(X,Y,phi,VocabClass,VocabClassSize):\n",
    "    Y_pred = [0]*(Y.shape[0])\n",
    "    count = 0\n",
    "    minval = min(Y)\n",
    "    \n",
    "    for i,review in enumerate(X):\n",
    "        class_prob = [0.0]*len(VocabClass)\n",
    "\n",
    "        for word in review.split():\n",
    "            for j in range(len(VocabClass)):\n",
    "                if word in VocabClass[j]:\n",
    "                    class_prob[j] += VocabClass[j][word]\n",
    "                else:\n",
    "                    class_prob[j] += (float(LaplaceSmoothing)/float(VocabSize))\n",
    "                \n",
    "        for j in range(len(VocabClass)):\n",
    "            class_prob[j] += phi[j]\n",
    "            \n",
    "        # class_label = max(enumerate(class_prob, key=lambda x: x[1]))[0] + min(Y)\n",
    "        class_label, element = max(enumerate(class_prob), key=itemgetter(1))\n",
    "        class_label += minval\n",
    "        \n",
    "        Y_pred[i]   = class_label\n",
    "        \n",
    "        if class_label == Y[i]:\n",
    "            count+=1\n",
    "        \n",
    "        # print(class_prob, element, \"Predicted:\", class_label, \"Correct: \", Y[i])\n",
    "        # print(i)\n",
    "        \n",
    "    return count, Y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def f1_score(A,B):\n",
    "    conf_mat = np.zeros((5,5));\n",
    "    for i in range(B.shape[0]):\n",
    "        conf_mat[int(B[i]-1)][int(A[i]-1)] = conf_mat[int(B[i]-1)][int(A[i]-1)] + 1;\n",
    "    \n",
    "    p1 = np.zeros(5);\n",
    "    r1 = np.zeros(5);\n",
    "    f1 = np.zeros(5);\n",
    "\n",
    "    for i in range(5):\n",
    "        p1[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 0)[i])\n",
    "        r1[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 1)[i])\n",
    "        f1[i] = (2*p1[i]*r1[i])/(p1[i]+r1[i]);\n",
    "\n",
    "    return round(np.average(f1),5);\n",
    "\n",
    "correct, Y_pred_train = predict(X_train, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy = {}%\".format(round(100*float(correct)/float(len(X_train)),2)))\n",
    "# print(\"Macro F1 score =\", f1_score(Y_pred_train, Y_train))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy  = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))\n",
    "# print(\"Macro F1 score =\", f1_score(Y_pred_test, Y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy = 72.086%\n",
      "Test Set Accuracy = 66.564%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Part B\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Set Accuracy = 66.56%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Random Guessing\n",
    "def random_guessing():\n",
    "    Y_pred = np.zeros(len(Y_test))\n",
    "    count = 0\n",
    "    for i in range (Y_test.shape[0]):\n",
    "        class_label = np.random.randint(1,6)\n",
    "        Y_pred[i]   = class_label\n",
    "        if(class_label == Y_test[i]):\n",
    "            count+=1\n",
    "    return count, Y_pred\n",
    "\n",
    "correct, Y_pred = random_guessing()\n",
    "print(\"Random Prediction Accuracy (Test Set) = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))\n",
    "\n",
    "# Majority Prediction\n",
    "def majority_prediction():\n",
    "    Y_pred = np.zeros(len(Y_test))\n",
    "    count = 0\n",
    "    class_label, element = max(enumerate(phi), key=itemgetter(1))\n",
    "    class_label += 1\n",
    "    \n",
    "    for i in range (Y_test.shape[0]):        \n",
    "        Y_pred[i]   = class_label\n",
    "        if(class_label == Y_test[i]):\n",
    "            count+=1\n",
    "    return count, Y_pred\n",
    "\n",
    "correct, Y_pred = majority_prediction()\n",
    "print(\"Majority Prediction Accuracy (Test Set) = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Prediction Accuracy (Test Set) = 20.17%\n",
      "Majority Prediction Accuracy (Test Set) = 66.09%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Part C\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "confusion_matrix = np.zeros((5,5))\n",
    "for i in range(len(Y_test)):\n",
    "    confusion_matrix[Y_test[i]-1][Y_pred_test[i]-1] += 1\n",
    "print(confusion_matrix.astype(int))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   2    0    0   21  205]\n",
      " [   0    0    0   63  263]\n",
      " [   2    0    1  231  852]\n",
      " [   3    0    0  280 2825]\n",
      " [  14    0    0  202 9036]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Part D\n",
    "part_d = True\n",
    "train_data = preprocessing(load_data(train_path), part_d)\n",
    "test_data  = preprocessing(load_data(test_path), part_d)\n",
    "\n",
    "X_train = train_data['reviewText'].copy()\n",
    "Y_train = train_data['overall'].copy()\n",
    "\n",
    "X_test = test_data['reviewText'].copy()\n",
    "Y_test = test_data['overall'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train, Y_train)\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        if(VocabClass[i][x] <= 0):\n",
    "            print(\"ERROR FOR CLASS:\",i)\n",
    "        else:\n",
    "            VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))\n",
    "    \n",
    "correct, Y_pred_train = predict(X_train, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (stemmed data) = {}%\".format(round(100*float(correct)/float(len(X_train)),2)))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (stemmed data)  = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (stemmed data) = 72.09%\n",
      "Test Set Accuracy (stemmed data)  = 66.56%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# duffelzaar\n",
    "# Part E\n",
    "vectorizer = TfidfVectorizer(preprocessor=None,\n",
    "                            tokenizer = word_tokenize,\n",
    "                            analyzer='word',\n",
    "                            stop_words=None,\n",
    "                            strip_accents=None, \n",
    "                            lowercase=True,\n",
    "                            ngram_range=(1,3), \n",
    "                            min_df=0.0001, \n",
    "                            max_df=0.9,\n",
    "                            binary=False,\n",
    "                            norm='l2',\n",
    "                            use_idf=1,\n",
    "                            smooth_idf=1, \n",
    "                            sublinear_tf=1)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test  = vectorizer.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,Y_train)\n",
    "\n",
    "pred_mnb = mnb.predict(X_test)\n",
    "print(\"Feature Engineering Score:\",round(accuracy_score(Y_test,pred_mnb),3));"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature Engineering Score: 0.661\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Part F\n",
    "# correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy = {}%\".format(round(100*float(correct)/14000.0),2))\n",
    "print(\"Macro F1 score = \".format(f1_score(Y_pred_test, Y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Set Accuracy = 67%\n",
      "Macro F1 score = \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_32215/2420841967.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  p1[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 0)[i])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}