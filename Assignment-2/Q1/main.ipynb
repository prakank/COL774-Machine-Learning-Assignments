{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import classification_report, accuracy_score, mean_squared_error\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "def _stem(doc, p_stemmer, en_stop, return_tokens):\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    stopped_tokens = filter(lambda token: token not in en_stop, tokens)\n",
    "    stemmed_tokens = map(lambda token: p_stemmer.stem(token), stopped_tokens)\n",
    "    if not return_tokens:\n",
    "        return ' '.join(stemmed_tokens)\n",
    "    return list(stemmed_tokens)\n",
    "\n",
    "def getStemmedDocuments(docs, return_tokens=False):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            docs: str/list(str): document or list of documents that need to be processed\n",
    "            return_tokens: bool: return a re-joined string or tokens\n",
    "        Returns:\n",
    "            str/list(str): processed document or list of processed documents\n",
    "        Example: \n",
    "            new_text = \"It is important to by very pythonly while you are pythoning with python. \\\n",
    "                All pythoners have pythoned poorly at least once.\"\n",
    "            print(getStemmedDocuments(new_text))\n",
    "        Reference: https://pythonprogramming.net/stemming-nltk-tutorial/\n",
    "    \"\"\"\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    if isinstance(docs, list):\n",
    "        output_docs = []\n",
    "        for item in docs:\n",
    "            output_docs.append(_stem(item, ps, en_stop, return_tokens))\n",
    "        return output_docs\n",
    "    else:\n",
    "        return _stem(docs, ps, en_stop, return_tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "nltk.download()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "LaplaceSmoothing = 1\n",
    "BASE_DIR = \"../\"\n",
    "train_path = os.path.join(BASE_DIR, 'data', 'reviews_Digital_Music_5.json', 'Music_Review_train.json')\n",
    "test_path  = os.path.join(BASE_DIR, 'data', 'reviews_Digital_Music_5.json', 'Music_Review_test.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def load_data(filename):\n",
    "    return pd.read_json(filename, lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def clean_data(line):\n",
    "    line = line.strip().lower()\n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "    line = re.sub('\\r?\\n',' ',line)\n",
    "    return line\n",
    "\n",
    "def preprocessing(df, stemming):\n",
    "    ColumnsToDrop = ['reviewerID', 'asin', 'reviewerName', 'unixReviewTime', 'reviewTime']\n",
    "    df = df.drop(ColumnsToDrop, axis=1)\n",
    "    \n",
    "    df['reviewText'] = df['reviewText'].apply(lambda x: clean_data(x))\n",
    "    df['summary']    = df['summary'].apply(lambda x: clean_data(x))\n",
    "    \n",
    "    if stemming:\n",
    "        df['reviewText'] = df['reviewText'].apply(lambda x: getStemmedDocuments(x))\n",
    "        df['summary']    = df['summary'].apply(lambda x: getStemmedDocuments(x))\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def Vocab_generation(df1, df2):\n",
    "    VocabSize = 0\n",
    "    Vocab = dict()\n",
    "    \n",
    "    min_val = min(df2)\n",
    "    max_val = max(df2)\n",
    "    \n",
    "    VocabClassSize = [0]*(max_val - min_val + 1)\n",
    "    ExampleSize    = [0]*(max_val - min_val + 1)    \n",
    "        \n",
    "    for i,review in enumerate(df1):\n",
    "        for word in review.split():\n",
    "            if len(word) > 0 and word not in Vocab:\n",
    "                Vocab[word] = 1\n",
    "                VocabSize  += 1\n",
    "\n",
    "    VocabClass = []\n",
    "    for i in range(max_val - min_val + 1):\n",
    "        d = Vocab.copy()\n",
    "        VocabClass.append(d)\n",
    "    \n",
    "    for i,review in enumerate(df1):\n",
    "        ExampleSize[df2[i]-min_val] += 1\n",
    "        for word in review.split():\n",
    "            if len(word) > 0:\n",
    "                VocabClassSize[df2[i]-min_val] += 1\n",
    "                VocabClass[df2[i]-min_val][word] += 1\n",
    "    \n",
    "    return Vocab, VocabClass, VocabSize, VocabClassSize, ExampleSize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "part_d = False\n",
    "\n",
    "train_data = preprocessing(load_data(train_path), part_d)\n",
    "test_data  = preprocessing(load_data(test_path), part_d)\n",
    "\n",
    "X_train = train_data['reviewText'].copy()\n",
    "Y_train = train_data['overall'].copy()\n",
    "\n",
    "X_test = test_data['reviewText'].copy()\n",
    "Y_test = test_data['overall'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# v1, v2, v3, v4, v5 = Vocab, VocabClass, VocabSize, VocabClassSize, phi\n",
    "# print(phi)\n",
    "# print(VocabClassSize)\n",
    "# # print(VocabClass)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2529, 2638, 5634, 13267, 25932]\n",
      "[327247, 468906, 1178141, 2886449, 4931491]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# [2529, 2638, 5634, 13267, 25932]\n",
    "# [328626, 470556, 1183227, 2902715, 4954673]\n",
    "# [328626, 470556, 1183227, 2902715, 4954673]\n",
    "\n",
    "# for i in range(len(VocabClass)):\n",
    "#     for x in VocabClass[i]:\n",
    "#         if(VocabClass[i][x] <= 0):\n",
    "#             print(\"ERROR\",i,x)\n",
    "#         else:\n",
    "#             np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "# print(\"DONE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "    \n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def predict(X,Y,phi,VocabClass,VocabClassSize):\n",
    "    Y_pred = [0]*(Y.shape[0])\n",
    "    count = 0\n",
    "    minval = min(Y)\n",
    "    \n",
    "    for i,review in enumerate(X):\n",
    "        class_prob = [0.0]*len(VocabClass)\n",
    "\n",
    "        for word in review.split():\n",
    "            for j in range(len(VocabClass)):\n",
    "                if word in VocabClass[j]:\n",
    "                    class_prob[j] += VocabClass[j][word]\n",
    "                else:\n",
    "                    class_prob[j] += (float(LaplaceSmoothing)/float(VocabSize))\n",
    "                \n",
    "        for j in range(len(VocabClass)):\n",
    "            class_prob[j] += phi[j]\n",
    "            \n",
    "        # class_label = max(enumerate(class_prob, key=lambda x: x[1]))[0] + min(Y)\n",
    "        class_label, element = max(enumerate(class_prob), key=itemgetter(1))\n",
    "        class_label += minval\n",
    "        \n",
    "        Y_pred[i]   = class_label\n",
    "        \n",
    "        if class_label == Y[i]:\n",
    "            count+=1\n",
    "        \n",
    "        # print(class_prob, element, \"Predicted:\", class_label, \"Correct: \", Y[i])\n",
    "        # print(i)\n",
    "        \n",
    "    return count, Y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "def f1_score(A,B):\n",
    "    conf_mat = np.zeros((5,5));\n",
    "    for i in range(B.shape[0]):\n",
    "        conf_mat[int(B[i]-1)][int(A[i]-1)] += 1;\n",
    "    \n",
    "    precision = np.zeros(5);\n",
    "    recall = np.zeros(5);\n",
    "    f1 = np.zeros(5);\n",
    "\n",
    "    for i in range(5):\n",
    "        precision[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 0)[i])\n",
    "        recall[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 1)[i])\n",
    "        f1[i] = (2*precision[i]*recall[i])/(precision[i]+recall[i]);\n",
    "\n",
    "    return f1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "correct, Y_pred_train = predict(X_train, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy = {}%\".format(round(100*float(correct)/float(len(X_train)),2)))\n",
    "# print(\"Macro F1 score =\", f1_score(Y_pred_train, Y_train))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy  = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))\n",
    "# print(\"Macro F1 score =\", f1_score(Y_pred_test, Y_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Part B\n",
    "\n",
    "# Random Guessing\n",
    "def random_guessing(Y_test):\n",
    "    Y_pred = np.zeros(len(Y_test))\n",
    "    count = 0\n",
    "    for i in range (Y_test.shape[0]):\n",
    "        class_label = np.random.randint(1,6)\n",
    "        Y_pred[i]   = class_label\n",
    "        if(class_label == Y_test[i]):\n",
    "            count+=1\n",
    "    return count, Y_pred\n",
    "\n",
    "correct, Y_pred = random_guessing(Y_test)\n",
    "print(\"Random Prediction Accuracy (Test Set) = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))\n",
    "\n",
    "# Majority Prediction\n",
    "def majority_prediction(Y_test):\n",
    "    Y_pred = np.zeros(len(Y_test))\n",
    "    count = 0\n",
    "    class_label, element = max(enumerate(phi), key=itemgetter(1))\n",
    "    class_label += 1\n",
    "    \n",
    "    for i in range (Y_test.shape[0]):        \n",
    "        Y_pred[i]   = class_label\n",
    "        if(class_label == Y_test[i]):\n",
    "            count+=1\n",
    "    return count, Y_pred\n",
    "\n",
    "correct, Y_pred = majority_prediction(Y_test)\n",
    "print(\"Majority Prediction Accuracy (Test Set) = {}%\".format(round(100*float(correct)/float(len(X_test)),2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Prediction Accuracy (Test Set) = 20.79%\n",
      "Majority Prediction Accuracy (Test Set) = 66.09%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Part C\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "confusion_matrix = np.zeros((5,5))\n",
    "for i in range(len(Y_test)):\n",
    "    confusion_matrix[Y_test[i]-1][Y_pred_test[i]-1] += 1\n",
    "print(confusion_matrix.astype(int))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   2    0    7   36  183]\n",
      " [   0    0    7  102  217]\n",
      " [   1    0    4  349  732]\n",
      " [   2    0    1  462 2643]\n",
      " [   7    1    7  397 8840]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Part D\n",
    "part_d = True\n",
    "train_data = preprocessing(load_data(train_path), part_d)\n",
    "test_data  = preprocessing(load_data(test_path), part_d)\n",
    "\n",
    "X_train = train_data['reviewText'].copy()\n",
    "Y_train = train_data['overall'].copy()\n",
    "\n",
    "X_test = test_data['reviewText'].copy()\n",
    "Y_test = test_data['overall'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "correct, Y_pred_train = predict(X_train, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (stemmed data) = {}%\".format(round(100*float(correct)/float(len(X_train)),5)))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (stemmed data)  = {}%\".format(round(100*float(correct)/float(len(X_test)),5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (stemmed data) = 69.704%\n",
      "Test Set Accuracy (stemmed data)  = 66.2%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Part E\n",
    "# Bigrams\n",
    "\n",
    "def bigrams(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        review = X[i]\n",
    "        token  = nltk.word_tokenize(review)\n",
    "        bigrams = list(ngrams(token,2))\n",
    "        bigrams = list(map(lambda x: \"_\".join(x), bigrams))\n",
    "        X[i] = \" \".join(bigrams)\n",
    "    return X\n",
    "\n",
    "X_train_b = bigrams(X_train.copy())\n",
    "X_test_b  = bigrams(X_test.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train_b, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "correct, Y_pred_train = predict(X_train_b, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (bigram data) = {}%\".format(round(100*float(correct)/float(len(X_train_b)),5)))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test_b, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (bigram data)  = {}%\".format(round(100*float(correct)/float(len(X_test_b)),5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (bigram data) = 96.236%\n",
      "Test Set Accuracy (bigram data)  = 66.61429%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# print(Y_test.shape, len(Y_pred_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# print(Y_pred_test.dtype)\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(np.array(Y_pred_test),Y_test,average=None))\n",
    "print(f1_score(np.array(Y_pred_test),Y_test,average='macro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.00873362 0.         0.00910747 0.12780749 0.80337948]\n",
      "0.18980561268791482\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Part E\n",
    "# Skip grams\n",
    "from nltk.util import skipgrams\n",
    "def gen_skipgrams(X,skip_dist=1):\n",
    "    for i in range(X.shape[0]):\n",
    "        review = X[i].split()\n",
    "        sg = list(skipgrams(review,2,skip_dist))\n",
    "        sg = list(map(lambda x: \"_\".join(x), sg))\n",
    "        X[i] = \" \".join(sg)\n",
    "    return X\n",
    "\n",
    "X_train_s = gen_skipgrams(X_train.copy())\n",
    "X_test_s  = gen_skipgrams(X_test.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train_s, Y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(VocabClassSize,VocabSize)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[347214, 496841, 1260629, 3132210, 5319120] 4475388\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "correct1, Y_pred_train = predict(X_train_s, Y_train, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (skip-gram data) = {}%\".format(round(100*float(correct1)/float(len(X_train_s)),5)))\n",
    "\n",
    "correct2, Y_pred_test = predict(X_test_s, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (skip-gram data)  = {}%\".format(round(100*float(correct2)/float(len(X_test_s)),5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (bigram data) = 96.232%\n",
      "Test Set Accuracy (bigram data)  = 66.45714%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "X_train_summary = train_data['summary'].copy()\n",
    "Y_train_summary = train_data['overall'].copy()\n",
    "\n",
    "X_test_summary = test_data['summary'].copy()\n",
    "Y_test_summary = test_data['overall'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train_summary, Y_train_summary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train_summary)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "correct, Y_pred_train = predict(X_train_summary, Y_train_summary, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (stemmed data) = {}%\".format(round(100*float(correct)/float(len(X_train_summary)),5)))\n",
    "\n",
    "correct, Y_pred_test = predict(X_test_summary, Y_test_summary, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (stemmed data)  = {}%\".format(round(100*float(correct)/float(len(X_test_summary)),5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (stemmed data) = 66.81%\n",
      "Test Set Accuracy (stemmed data)  = 67.27143%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "X_train_bi = gen_skipgrams(X_train_summary.copy())\n",
    "X_test_bi  = gen_skipgrams(X_test_summary.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "Vocab, VocabClass, VocabSize, VocabClassSize, phi = Vocab_generation(X_train_bi, Y_train_summary)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "for i in range(len(VocabClass)):\n",
    "    for x in VocabClass[i]:\n",
    "        VocabClass[i][x] = np.log(float(VocabClass[i][x])/float(VocabClassSize[i] + VocabSize))\n",
    "\n",
    "for i in range(len(VocabClass)):\n",
    "    phi[i] = np.log(float(phi[i])/float(len(X_train_bi)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "correct, Y_pred_train_bi = predict(X_train_bi, Y_train_summary, phi, VocabClass, VocabClassSize)\n",
    "print(\"Train Set Accuracy (bigram data) = {}%\".format(round(100*float(correct)/float(len(X_train_bi)),5)))\n",
    "\n",
    "correct, Y_pred_test_bi = predict(X_test_bi, Y_test_summary, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy (bigram data)  = {}%\".format(round(100*float(correct)/float(len(X_test_bi)),5)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Set Accuracy (bigram data) = 84.664%\n",
      "Test Set Accuracy (bigram data)  = 66.80714%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Train Set Accuracy (bigram data) = 95.592%\n",
    "# Test Set Accuracy (bigram data)  = 66.32857%\n",
    "# [517029, 741306, 1882494, 4678420, 7939810] 6369181\n",
    "print(VocabClassSize,VocabSize)\n",
    "# duffelzaar\n",
    "# # Part E\n",
    "# vectorizer = TfidfVectorizer(preprocessor=None,\n",
    "#                             tokenizer = word_tokenize,\n",
    "#                             analyzer='word',\n",
    "#                             stop_words=None,\n",
    "#                             strip_accents=None, \n",
    "#                             lowercase=True,\n",
    "#                             ngram_range=(1,3), \n",
    "#                             min_df=0.0001, \n",
    "#                             max_df=0.9,\n",
    "#                             binary=False,\n",
    "#                             norm='l2',\n",
    "#                             use_idf=1,\n",
    "#                             smooth_idf=1, \n",
    "#                             sublinear_tf=1)\n",
    "\n",
    "# X_train = vectorizer.fit_transform(X_train)\n",
    "# X_test  = vectorizer.transform(X_test)\n",
    "\n",
    "# mnb = MultinomialNB()\n",
    "# mnb.fit(X_train,Y_train)\n",
    "\n",
    "# pred_mnb = mnb.predict(X_test)\n",
    "# print(\"Feature Engineering Score:\",round(accuracy_score(Y_test,pred_mnb),3));"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature Engineering Score: 0.661\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Part F\n",
    "# correct, Y_pred_test = predict(X_test, Y_test, phi, VocabClass, VocabClassSize)\n",
    "print(\"Test Set Accuracy = {}%\".format(round(100*float(correct)/14000.0),2))\n",
    "print(\"Macro F1 score = \".format(f1_score(Y_pred_test, Y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Set Accuracy = 67%\n",
      "Macro F1 score = \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_32215/2420841967.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  p1[i] = conf_mat[i,i]/(np.sum(conf_mat, axis = 0)[i])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def add(x):\n",
    "    return x+2\n",
    "L = [1,2,3]\n",
    "df_temp = pd.DataFrame(L)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df_temp.apply(lambda x: add(x))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  3\n",
       "1  4\n",
       "2  5"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "df_temp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}